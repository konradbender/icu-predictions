{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did provide the file ``` requirements.txt ``` though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import data\n",
    "import preprocessing\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import score_submission\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from threading import Thread\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Pre Processing\n",
    "\n",
    "As described above, the train and test features contain a lot of missing values. Therefore, we need to develop a\n",
    "strategy to deal with these missing values. In a nutshell, we are imputing with the median value for each feature\n",
    "and standardizing each feature to zero mean and unit variance. This is happening in a number of steps\n",
    "\n",
    "1. ```preprocessing.prepare_features()``` Fills up values for each for each patient based on their data. This means\n",
    "that if patient ```i```has a missing feature at a certain timestamp, it will be filled up with the median from the other\n",
    "timestamps. Important: If a patient is missing a value for a feature fora all timestamps, those values are left as\n",
    " missing and will be filled up in a next step. Finally, each patient is flattened into a single row vector.\n",
    "\n",
    "2. ```preprocessing.impute_features()``` Looks at the flattened vectors of patients in the train and test dataset. Here,\n",
    "missing values are again imputed based on the median, so if patient ```i```was missing values for blood pressure at all\n",
    "timestamps, then those are filled up here with the median blood pressure of all patients for each timestamp ```j```.\n",
    "After calling this method, the train and test features will not contain any ```np.nan```anymore.\n",
    "\n",
    "3. ```preprocessing.standardize_features()``` standardizes the features to unit variance and zero mean over train and\n",
    "test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_train_features = data.get_training_features()\n",
    "raw_train_labels = data.get_training_labels()\n",
    "\n",
    "reshaped_train_features = preprocessing.prepare_features(raw_train_features, read_from_file=False)\n",
    "\n",
    "# make a split\n",
    "s_train_features, s_test_features, s_train_labels, s_test_labels = train_test_split(\n",
    "    reshaped_train_features, raw_train_labels,  test_size = 0.33)\n",
    "\n",
    "\n",
    "# fill out values that were not imputed in last step becasue a patient was missing all of them\n",
    "train, test = preprocessing.impute_features(s_train_features,s_test_features)\n",
    "\n",
    "train_features, test_features = preprocessing.standardize_features(train, test)\n",
    "train_labels = s_train_labels\n",
    "test_labels = s_test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "classification_labels = ['LABEL_BaseExcess','LABEL_Fibrinogen','LABEL_AST','LABEL_Alkalinephos',\n",
    " 'LABEL_Bilirubin_total','LABEL_Lactate','LABEL_TroponinI','LABEL_SaO2',\n",
    " 'LABEL_Bilirubin_direct','LABEL_EtCO2','LABEL_Sepsis']\n",
    "\n",
    "\n",
    "classification_params = {'loss': 'deviance', 'random_state': 0}\n",
    "\n",
    "classification_models = {label : GradientBoostingClassifier(**classification_params) for label in classification_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_labels = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "def cv_scoring_method(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return r2_score(y,y_pred)\n",
    "\n",
    "cv_splitter = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "regression_parameters = {'fit_intercept':True, 'scoring':cv_scoring_method, 'cv': cv_splitter}\n",
    "\n",
    "regression_models = {key:RidgeCV(**regression_parameters) for key in regression_labels}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = {**regression_models, **classification_models}\n",
    "\n",
    "threads = list()\n",
    "\n",
    "for label, model in models.items():\n",
    "    thread = Thread(target=model.fit, args=[train_features,train_labels[label]])\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = pd.DataFrame(index=test_features.index, columns=[*classification_labels,*regression_labels])\n",
    "\n",
    "for label in classification_labels:\n",
    "    result[label] =  models[label].predict_proba(test_features)[:,1]\n",
    "\n",
    "for label in regression_labels:\n",
    "    result[label] = models[label].predict(test_features)\n",
    "\n",
    "\n",
    "score_submission.get_score(test_labels,result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "curves = {label: roc_curve(test_labels[label],result[label]) for label in classification_labels}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(4)\n",
    "\n",
    "for label, curve in curves.items():\n",
    "    fpr, tpr, threshold = curve\n",
    "    name = label.split('_')\n",
    "    ax.plot(fpr,tpr, label=name[1])\n",
    "ax.legend(loc = 'center left', bbox_to_anchor=(1,0.5))\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('Receiver Operator Curve')\n",
    "plt.show()\n",
    "fig.set_figwidth(7)\n",
    "fig.tight_layout()\n",
    "fig.savefig('plot.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_labels.set_index('pid', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(test_labels.shape)\n",
    "deltas = pd.DataFrame(index=test_labels.index, columns = regression_labels)\n",
    "\n",
    "for label in regression_labels:\n",
    "    delta =  result.loc[:,label].subtract(test_labels.loc[:,label])\n",
    "    delta = delta.divide(test_labels[label])\n",
    "    deltas[label] = delta\n",
    "#    deltas.assign(delta)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('start')\n",
    "ax = sb.kdeplot(data = deltas,  fill=False, legend = True)\n",
    "\n",
    "ax.set_xlim((-0.5,0.5))\n",
    "leg = ax.get_legend()\n",
    "texts = leg.get_texts()\n",
    "for index, text in enumerate(texts):\n",
    "    text = text.get_text()\n",
    "    split = text.split('_')\n",
    "    texts[index].set_text(split[1])\n",
    "ax.set_title('Normalized Residuals')\n",
    "plt.savefig('hist.png', dpi=300)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del ax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}